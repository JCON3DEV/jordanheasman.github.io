<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Documentation Governance at Scale</title>
  <meta property="og:title" content="Documentation Governance at Scale" />
  <meta property="og:image" content="/img/jordan-heasman.png" />
  <meta name="description" content="Contract-driven metadata governance system for Real-Time CDP edition correctness at scale.">
  <meta property="og:description" content="Contract-driven metadata governance system for Real-Time CDP edition correctness at scale." />
  <meta name="author" content="Jordan Heasman">
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">
  
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
  <link href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" rel="stylesheet">
  <link href='https://cdnjs.cloudflare.com/ajax/libs/devicons/1.8.0/css/devicons.min.css' rel='stylesheet'>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/simple-line-icons/2.4.1/css/simple-line-icons.min.css" rel="stylesheet">
  
  <link href="/css/resume.css" rel="stylesheet">
  <link href="/css/tweaks.css" rel="stylesheet">
  <meta name="generator" content="Hugo 0.135.0">
  
   
  
</head>
<body id="page-top">
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
  <a class="navbar-brand js-scroll-trigger" href="#page-top">
    <span class="d-block d-lg-none">Jordan Heasman</span>
    <span class="d-none d-lg-block">
      <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="/img/jordan-heasman.png" alt="Jordan Heasman">
    </span>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#overview">Overview</a>
      </li>
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#work">Work</a>
      </li>
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#approach">Approach</a>
      </li>
      <li class="nav-item">
        <a class="nav-link js-scroll-trigger" href="/#background">Background</a>
      </li>
    </ul>
  </div>
</nav>

  <div class="container-fluid p-0">
    
<nav aria-label="breadcrumb">
  <ol class="breadcrumb">
    <li class="breadcrumb-item">
      <a href="/">Home</a>
    </li>
    <li class="breadcrumb-item">
      <a href="/work/">Work</a>
    </li>
    <li class="breadcrumb-item active">
      <span>Documentation Governance at Scale</span>
    </li>
  </ol>
</nav>

<section class="resume-section p-3 p-lg-5 d-flex d-column">
  <div class="my-auto">
    <h1 class="mb-0"><span class="text-primary">Documentation Governance at Scale</span></h1>
    <p>Contract-driven governance system to ensure edition-specific metadata consistency across Real-Time CDP documentation
      at scale.</p>
    
    <h3 id="business-problem">Business Problem</h3>
    <p>Real-Time Customer Data Platform documentation spans multiple editions: B2B, B2C, and B2P, each with different feature availability, packaging, and eligibility. At this scale, metadata accuracy is not cosmetic; it directly affects discoverability, trust, and downstream consumption by both humans and AI systems.</p>
    <p>The documentation footprint included:</p>
    <ul>
      <li>~90 pages scoped specifically to Real-Time CDP</li>
      <li>~1,970 files across the broader repository</li>
    </ul>
    <p>Within that environment, three failure modes were consistently observed:</p>
    <ul>
      <li>Missing or incorrect edition badges, causing features to appear available where they were not</li>
      <li>Inconsistent product metadata across conceptually similar pages</li>
      <li>Review gaps driven by scale, where full verification of edition correctness was not feasible during normal review cycles</li>
    </ul>
    <p>The impact was not limited to internal quality standards. Customers increasingly rely on Adobe AI Assistant to answer
      product questions, and that capability depends on accurate, consistent documentation metadata to return correct
      information. When metadata is wrong or incomplete, confidently incorrect answers reach customers and trust erodes.</p>
    <p>This was not a tooling problem. It was a governance problem under scale.</p>
    
    <h3 id="assumptions">Assumptions</h3>
    <p>Several assumptions shaped the approach from the outset:</p>
    <ul>
      <li>Metadata correctness is a governance responsibility, not an authoring preference</li>
      <li>Human review time is the most constrained and expensive resource</li>
      <li>Automated systems must surface signal, not take action</li>
      <li>Trust collapses quickly if automation produces noise, false positives, or unreviewed changes</li>
    </ul>
    <p>These assumptions were reinforced by hard constraints:</p>
    <ul>
      <li>No automated edits to documentation</li>
      <li>No automatic Jira ticket creation</li>
      <li>No low-confidence or speculative flags</li>
      <li>No changes unless a defined metadata contract is violated</li>
    </ul>
    <p>Organizationally, additional constraints applied:</p>
    <ul>
      <li>There was no mandate to change existing authoring workflows</li>
      <li>No additional reviewer headcount was available</li>
      <li>No centralized authority existed to police metadata consistency</li>
    </ul>
    <p>Any solution that required behavioral change, increased coordination overhead, or continuous manual triage would fail to scale and would not be adopted.</p>
    
    <h3 id="decision">Decision</h3>
    <p>The system was designed to support a single governance decision at scale: where human review effort should be applied
      for edition correctness, and where it should not.</p>
    
    <blockquote>Which documents require human review for edition correctness right now—and which do not—without reviewing
      every page.</blockquote>
    
    <p>Before this, that decision was effectively unavailable. Edition-specific correctness could not be assessed reliably
      across the corpus without manual sampling and spot checks. Reviewers relied on partial coverage and time-boxed
      inspection, which made it difficult to reason about risk accumulation across the platform.</p>
    
    <p>The risk of inaction was clear:</p>
    <ul>
      <li>Incorrect edition attribution would propagate into customer-facing guidance</li>
      <li>Customers would receive confidently wrong answers when relying on downstream systems</li>
      <li>Trust in documentation—and by extension the platform—would degrade over time</li>
    </ul>
    
    <p>The goal was not to fix metadata automatically. The goal was to direct reviewers to the smallest possible set of
      pages that demonstrably require attention, using high-confidence signals and remaining silent when no action is
      required.</p>
    
    <h3 id="intervention">Intervention</h3>
    <p>The intervention was a governance support system designed to evaluate metadata correctness at scale and surface
      review-worthy signals only. It does not modify documentation, create work items, or attempt to "fix" issues
      automatically.</p>
    
    <p>The system operates against a defined metadata contract that specifies required edition badges and product metadata
      for Real-Time Customer Data Platform content. That contract serves as the single source of truth for evaluation.</p>
    
    <p>Each documentation run is processed as follows:</p>
    <ul>
      <li>Documentation content is scanned in bulk against the metadata contract</li>
      <li>Edition-specific requirements are evaluated deterministically</li>
      <li>Signals are produced only when a contract violation is detected</li>
      <li>Results are filtered to exclude low-confidence or ambiguous cases</li>
      <li>When no violation is found, the system remains silent</li>
    </ul>
    
    <p>This design produces fewer, higher-confidence signals rather than exhaustive lists of potential issues.</p>
    
    <p>The system explicitly avoids:</p>
    <ul>
      <li>Automated edits to documentation</li>
      <li>Automatic Jira ticket creation</li>
      <li>Broad "linting" or advisory warnings</li>
      <li>Any output that would require interpretation or follow-up investigation</li>
    </ul>
    
    <p>Human reviewers remain the decision-makers. The system’s role is to narrow the review surface area so effort is spent
      where it is most needed.</p>
    
    <p><strong>System flow (single diagram)</strong></p>
    <pre><code>    Documentation repository
              ↓
    Edition metadata contract
              ↓
    Deterministic bulk scan
              ↓
    Confidence-gated signals
              ↓
    Targeted human review</code></pre>
    
    <p>By separating detection from action, the system supports governance at scale without introducing workflow disruption
      or false confidence.</p>
    
    <h3 id="result">Result</h3>
    <p>The primary outcome of this work was not improved metadata in isolation, but the introduction of a scalable governance capability for edition-specific documentation.</p>
    <p>The system enabled reviewers and platform leadership to:</p>
    <ul>
      <li>Focus human review effort on a small, well-defined subset of documents that demonstrably violate edition requirements</li>
      <li>Treat silence as a signal of confidence, rather than absence of coverage</li>
      <li>Reason about metadata risk across the Real-Time CDP documentation set without exhaustive manual inspection</li>
        <li>Detect consistency issues early, before they propagate into customer-facing guidance and downstream AI responses</li>
    </ul>
    <p>Just as importantly, the system established clear operational boundaries:</p>
    <ul>
      <li>Automated evaluation without automated action</li>
      <li>High-confidence signals without background noise</li>
      <li>Governance support without workflow disruption</li>
    </ul>
    <p>This shifted metadata review from a reactive, sample-based activity to a repeatable, contract-driven process that can be rerun as documentation evolves, editions change, or new content is introduced.</p>
    <p>The result is not faster documentation production, but more reliable decision-making at scale, with human judgment preserved and trust maintained.</p>
    
    <h3>Tags</h3>
    <ul class="tags">
      <li><a class="tag" href="/tags/documentation-systems/">Documentation Systems</a></li>
      <li><a class="tag" href="/tags/governance/">Governance</a></li>
      <!-- Doesnt exist yet: <li><a class="tag" href="/tags/metadata-governance/">Metadata Governance</a></li> -->

    </ul>
    
    <hr>
    <p><a href="/work/">← Back to Work</a></p>

  </div>
</section>


  
  </div>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0/js/bootstrap.bundle.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
  
  <script src="/js/resume.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-X13ZLN4TK9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-X13ZLN4TK9');
  </script>
  

  
</body>
</html>

